{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30443934",
   "metadata": {},
   "source": [
    "# Homework Reflections – Weeks 9, 11, and 12\n",
    "\n",
    "This notebook collects all code used for the reflections:\n",
    "- Week 9: Heteroskedasticity, correlated errors, and bootstrap vs full DGP\n",
    "- Week 11: Event study dataset and model\n",
    "- Week 12: Difference-in-differences with violated prior trends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04acc23",
   "metadata": {},
   "source": [
    "## Week 9 – Simulation Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e2134",
   "metadata": {},
   "source": [
    "### Week 9 \n",
    "**Question 1:**\n",
    "Write code that uses a simulation to estimate the standard deviation of the coefficient when there is heteroskedasticity, and compare these standard errors to those from OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b372eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.16.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Downloading statsmodels-0.14.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [statsmodels]\u001b[0m [statsmodels]\n",
      "\u001b[1A\u001b[2KSuccessfully installed patsy-1.0.2 statsmodels-0.14.6\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c438e55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emp_sd_beta_hat': np.float64(0.10673306927024596),\n",
       " 'mean_se_conventional': np.float64(0.07510474786708725),\n",
       " 'mean_se_hc1': np.float64(0.111413843051685)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "def sim_hetero_once(n=1000, beta=1.0, sigma=1.0, h=1.5):\n",
    "    \"\"\"DGP: Y = beta*X + e, with heteroskedastic errors: Var(e|X) = sigma^2*(1 + h*|X|)^2\"\"\"\n",
    "    X = rng.normal(0, 1, n)\n",
    "    e = rng.normal(0, sigma * (1 + h * np.abs(X)))\n",
    "    Y = beta * X + e\n",
    "    X1 = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X1).fit()\n",
    "    # HC1 robust\n",
    "    model_hc1 = model.get_robustcov_results(cov_type=\"HC1\")\n",
    "    return {\n",
    "        \"beta_hat\": model.params[1],\n",
    "        \"se_conventional\": model.bse[1],\n",
    "        \"se_hc1\": model_hc1.bse[1]\n",
    "    }\n",
    "\n",
    "def sim_hetero_many(R=1000, n=1000, beta=1.0, sigma=1.0, h=1.5):\n",
    "    out = [sim_hetero_once(n=n, beta=beta, sigma=sigma, h=h) for _ in range(R)]\n",
    "    bhats = np.array([d[\"beta_hat\"] for d in out])\n",
    "    se_conv = np.array([d[\"se_conventional\"] for d in out])\n",
    "    se_hc1  = np.array([d[\"se_hc1\"] for d in out])\n",
    "    return {\n",
    "        \"emp_sd_beta_hat\": bhats.std(ddof=1),\n",
    "        \"mean_se_conventional\": se_conv.mean(),\n",
    "        \"mean_se_hc1\": se_hc1.mean()\n",
    "    }\n",
    "\n",
    "res_het = sim_hetero_many(R=1000, n=1000, beta=1.0, sigma=1.0, h=1.5)\n",
    "res_het"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df92726e",
   "metadata": {},
   "source": [
    "### Week 9 \n",
    "**Question 2:** Use a simulation to estimate the standard deviation of the coefficient when errors are highly correlated / non-independent, and compare these standard errors to those from OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d6a023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emp_sd_beta_hat': np.float64(0.047369696301241354),\n",
       " 'mean_se_conventional': np.float64(0.04925726002263184),\n",
       " 'mean_se_cluster': np.float64(0.04872828437530312)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "def sim_cluster_once(G=100, m=10, beta=1.0, tau=1.2, sigma=1.0):\n",
    "    \"\"\"DGP: G clusters, m obs per cluster (n = G*m).\n",
    "    X ~ N(0,1); errors have cluster shock u_g and idiosyncratic v.\n",
    "    Y = beta*X + e,  e = u_g + v\n",
    "    \"\"\"\n",
    "    n = G * m\n",
    "    g_id = np.repeat(np.arange(G), m)\n",
    "    X = rng.normal(0, 1, n)\n",
    "    u = rng.normal(0, tau, G)  # cluster shocks\n",
    "    v = rng.normal(0, sigma, n)\n",
    "    e = u[g_id] + v\n",
    "    Y = beta * X + e\n",
    "    X1 = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X1).fit()\n",
    "    # Cluster-robust by group id\n",
    "    model_clu = model.get_robustcov_results(cov_type=\"cluster\", groups=g_id)\n",
    "    return {\n",
    "        \"beta_hat\": model.params[1],\n",
    "        \"se_conventional\": model.bse[1],\n",
    "        \"se_cluster\": model_clu.bse[1]\n",
    "    }\n",
    "\n",
    "def sim_cluster_many(R=1000, G=100, m=10, beta=1.0, tau=1.2, sigma=1.0):\n",
    "    out = [sim_cluster_once(G=G, m=m, beta=beta, tau=tau, sigma=sigma) for _ in range(R)]\n",
    "    bhats = np.array([d[\"beta_hat\"] for d in out])\n",
    "    se_conv = np.array([d[\"se_conventional\"] for d in out])\n",
    "    se_clu  = np.array([d[\"se_cluster\"] for d in out])\n",
    "    return {\n",
    "        \"emp_sd_beta_hat\": bhats.std(ddof=1),\n",
    "        \"mean_se_conventional\": se_conv.mean(),\n",
    "        \"mean_se_cluster\": se_clu.mean()\n",
    "    }\n",
    "\n",
    "res_cluster = sim_cluster_many(R=1000, G=100, m=10, beta=1.0, tau=1.2, sigma=1.0)\n",
    "res_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326684e4",
   "metadata": {},
   "source": [
    "### Week 9 \n",
    "bootstrap standard deviation of the coefficient (using naive iid residual bootstrap) can differ from the standard deviation from a full simulation of the DGP; show how this improves with a larger sample and a better bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "484b18f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'empirical_SD_DGP': np.float64(0.16722904846233982),\n",
       " 'SE_naive_IID_boot': np.float64(0.15280290929995982),\n",
       " 'SE_cluster_boot': np.float64(0.18480915168299267)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "def dgp_cluster(G=40, m=8, beta=1.0, tau=3.0, sigma=1.0):\n",
    "    \"\"\"Strong intra-cluster correlation: rho = tau^2 / (tau^2 + sigma^2) ≈ 0.9.\"\"\"\n",
    "    n = G*m\n",
    "    g = np.repeat(np.arange(G), m)\n",
    "    X = rng.normal(0, 1, n)\n",
    "    u = rng.normal(0, tau, G)         # cluster shock\n",
    "    v = rng.normal(0, sigma, n)       # idiosyncratic\n",
    "    e = u[g] + v\n",
    "    Y = beta*X + e\n",
    "    return Y, X, g\n",
    "\n",
    "def iid_resid_boot_se(Y, X, B=800):\n",
    "    X1 = sm.add_constant(X)\n",
    "    base = sm.OLS(Y, X1).fit()\n",
    "    resid = base.resid\n",
    "    betas = []\n",
    "    for _ in range(B):\n",
    "        e_star = rng.choice(resid, size=len(resid), replace=True)  # WRONG under dependence\n",
    "        Y_star = base.fittedvalues + e_star\n",
    "        betas.append(sm.OLS(Y_star, X1).fit().params[1])\n",
    "    return np.std(betas, ddof=1)\n",
    "\n",
    "def cluster_boot_se(Y, X, groups, B=800):\n",
    "    # Resample entire clusters (block bootstrap)\n",
    "    X1 = sm.add_constant(X)\n",
    "    base = sm.OLS(Y, X1).fit()\n",
    "    betas = []\n",
    "    gids = np.unique(groups)\n",
    "    idx_by_g = {g: np.where(groups==g)[0] for g in gids}\n",
    "    for _ in range(B):\n",
    "        sample_g = rng.choice(gids, size=len(gids), replace=True)\n",
    "        idx = np.concatenate([idx_by_g[g] for g in sample_g])\n",
    "        betas.append(sm.OLS(Y[idx], X1[idx]).fit().params[1])\n",
    "    return np.std(betas, ddof=1)\n",
    "\n",
    "def empirical_sd_over_dgp(R=800, **dgp_kwargs):\n",
    "    bhats = []\n",
    "    for _ in range(R):\n",
    "        Y, X, g = dgp_cluster(**dgp_kwargs)\n",
    "        bhats.append(sm.OLS(Y, sm.add_constant(X)).fit().params[1])\n",
    "    return np.std(bhats, ddof=1)\n",
    "\n",
    "G, m = 40, 8\n",
    "Y, X, g = dgp_cluster(G=G, m=m)\n",
    "emp_sd = empirical_sd_over_dgp(R=800, G=G, m=m)\n",
    "se_iid  = iid_resid_boot_se(Y, X, B=800)\n",
    "se_clust= cluster_boot_se(Y, X, g, B=800)\n",
    "\n",
    "small_sample_results = {\n",
    "    \"empirical_SD_DGP\": emp_sd,\n",
    "    \"SE_naive_IID_boot\": se_iid,\n",
    "    \"SE_cluster_boot\": se_clust\n",
    "}\n",
    "small_sample_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9827dfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'empirical_SD_DGP_big': np.float64(0.03560541140860346),\n",
       " 'SE_naive_IID_boot_big': np.float64(0.039213296878995545),\n",
       " 'SE_cluster_boot_big': np.float64(0.03751764290581541)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Larger sample: more clusters and/or size per cluster\n",
    "G, m = 400, 20\n",
    "Y_big, X_big, g_big = dgp_cluster(G=G, m=m)\n",
    "emp_sd_big = empirical_sd_over_dgp(R=400, G=G, m=m)\n",
    "se_iid_big  = iid_resid_boot_se(Y_big, X_big, B=400)\n",
    "se_clust_big= cluster_boot_se(Y_big, X_big, g_big, B=400)\n",
    "\n",
    "large_sample_results = {\n",
    "    \"empirical_SD_DGP_big\": emp_sd_big,\n",
    "    \"SE_naive_IID_boot_big\": se_iid_big,\n",
    "    \"SE_cluster_boot_big\": se_clust_big\n",
    "}\n",
    "large_sample_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26457e",
   "metadata": {},
   "source": [
    "## Week 11 – Event Study Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4d06f",
   "metadata": {},
   "source": [
    "### Week 11 \n",
    "**Question 1(a):** Construct a dataset for an event study where the value, derivative, and second derivative of a trend all change discontinuously after an event, and build a model using only the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c1c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 3.715e+04\n",
      "Date:                Sun, 07 Dec 2025   Prob (F-statistic):          9.94e-270\n",
      "Time:                        06:10:51   Log-Likelihood:                -860.88\n",
      "No. Observations:                 200   AIC:                             1730.\n",
      "Df Residuals:                     196   BIC:                             1743.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         44.5678      3.992     11.164      0.000      36.695      52.441\n",
      "x1           228.1174      5.119     44.567      0.000     218.023     238.212\n",
      "x2            -2.8714      0.095    -30.076      0.000      -3.060      -2.683\n",
      "x3             0.0411      0.000     95.674      0.000       0.040       0.042\n",
      "==============================================================================\n",
      "Omnibus:                       22.282   Durbin-Watson:                   0.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.093\n",
      "Skew:                          -0.843   Prob(JB):                     2.16e-06\n",
      "Kurtosis:                       3.535   Cond. No.                     7.50e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.5e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Event coefficient (beta_event): 228.11741972056552\n",
      "p-value for event effect: 1.6033894029514882e-104\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set up time and event\n",
    "T = 200\n",
    "t = np.arange(T)\n",
    "event_time = 100\n",
    "post = (t > event_time).astype(int)\n",
    "\n",
    "# Construct Y with different level, slope, and curvature after the event\n",
    "# Pre-event: mild quadratic\n",
    "# Post-event: bigger intercept, steeper slope, more curvature\n",
    "Y = np.where(\n",
    "    t <= event_time,\n",
    "    0.01 * t**2 + 0.1 * t,                       # pre-event trend\n",
    "    (0.03 * t**2 + 0.6 * t + 10),                # post-event trend: level, slope, curvature all changed\n",
    ")\n",
    "\n",
    "# Add noise\n",
    "Y = Y + np.random.normal(0, 1, size=T)\n",
    "\n",
    "# Model using ONLY the value (no explicit derivatives),\n",
    "# but allowing for a general trend via t and t^2\n",
    "X = np.column_stack([post, t, t**2])   # event indicator + time + time^2\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# The key question: is the event \"real\"?\n",
    "# That is, is the coefficient on `post` (the event dummy) significantly nonzero?\n",
    "beta_event = model.params[1]\n",
    "pval_event = model.pvalues[1]\n",
    "print(\"Event coefficient (beta_event):\", beta_event)\n",
    "print(\"p-value for event effect:\", pval_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d10e6f",
   "metadata": {},
   "source": [
    "## Week 12 – Difference-in-Differences with Violated Prior Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b9067",
   "metadata": {},
   "source": [
    "### Week 12 \n",
    "**Question:** Construct a dataset in which prior trends do not hold, and in which this makes the differences-in-differences estimate come out wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7505e0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.769\n",
      "Model:                            OLS   Adj. R-squared:                  0.769\n",
      "Method:                 Least Squares   F-statistic:                     2220.\n",
      "Date:                Sun, 07 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        06:11:26   Log-Likelihood:                -3612.9\n",
      "No. Observations:                2000   AIC:                             7234.\n",
      "Df Residuals:                    1996   BIC:                             7256.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          -1.5350      0.066    -23.274      0.000      -1.664      -1.406\n",
      "Group          -1.5205      0.093    -16.301      0.000      -1.703      -1.338\n",
      "Post            2.5179      0.093     26.995      0.000       2.335       2.701\n",
      "interaction     4.5820      0.132     34.737      0.000       4.323       4.841\n",
      "==============================================================================\n",
      "Omnibus:                        7.589   Durbin-Watson:                   0.907\n",
      "Prob(Omnibus):                  0.022   Jarque-Bera (JB):                6.705\n",
      "Skew:                           0.084   Prob(JB):                       0.0350\n",
      "Kurtosis:                       2.772   Cond. No.                         6.85\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "True treatment effect: 2.0\n",
      "Estimated DID effect: 4.582018337941185\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of observations per (group, time) cell\n",
    "n_per_cell = 100\n",
    "\n",
    "# Time periods and groups\n",
    "times = np.arange(-5, 5)        # -5, -4, ..., 4\n",
    "groups = np.array([0, 1])       # 0 = control, 1 = treatment\n",
    "\n",
    "# Create all (time, group) combinations and repeat within each cell\n",
    "time_grid, group_grid = np.meshgrid(times, groups, indexing='ij')\n",
    "time_vec = np.repeat(time_grid.ravel(), n_per_cell)\n",
    "group_vec = np.repeat(group_grid.ravel(), n_per_cell)\n",
    "\n",
    "# Indicator for post-treatment period\n",
    "post = (time_vec >= 0).astype(int)\n",
    "\n",
    "# Different pre-trends: treatment group has a steeper slope\n",
    "control_trend = 0.5 * time_vec\n",
    "treat_trend   = 1.0 * time_vec   # steeper line\n",
    "\n",
    "trend = np.where(group_vec == 0, control_trend, treat_trend)\n",
    "\n",
    "# True treatment effect\n",
    "true_effect = 2.0\n",
    "\n",
    "# Outcome with noise\n",
    "noise = np.random.normal(0, 1, len(time_vec))\n",
    "Y = trend + true_effect * post * group_vec + noise\n",
    "\n",
    "# Put into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Y\": Y,\n",
    "    \"Time\": time_vec,\n",
    "    \"Group\": group_vec,\n",
    "    \"Post\": post\n",
    "})\n",
    "\n",
    "# DID regression: Y ~ Group + Post + Group*Post\n",
    "df[\"interaction\"] = df[\"Group\"] * df[\"Post\"]\n",
    "X = sm.add_constant(df[[\"Group\", \"Post\", \"interaction\"]])\n",
    "res = sm.OLS(df[\"Y\"], X).fit()\n",
    "\n",
    "print(res.summary())\n",
    "print(\"True treatment effect:\", true_effect)\n",
    "print(\"Estimated DID effect:\", res.params[\"interaction\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
