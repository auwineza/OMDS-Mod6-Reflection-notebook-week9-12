{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30443934",
   "metadata": {},
   "source": [
    "# Homework Reflections – Weeks 9, 11, and 12\n",
    "\n",
    "This notebook collects all code used for the reflections:\n",
    "- Week 9: Heteroskedasticity, correlated errors, and bootstrap vs full DGP\n",
    "- Week 11: Event study dataset and model\n",
    "- Week 12: Difference-in-differences with violated prior trends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04acc23",
   "metadata": {},
   "source": [
    "## Week 9 – Simulation Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e2134",
   "metadata": {},
   "source": [
    "### Week 9 – Question 1\n",
    "**Task:** Write code that uses a simulation to estimate the standard deviation of the coefficient when there is heteroskedasticity, and compare these standard errors to those from OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "def sim_hetero_once(n=1000, beta=1.0, sigma=1.0, h=1.5):\n",
    "    \"\"\"DGP: Y = beta*X + e, with heteroskedastic errors: Var(e|X) = sigma^2*(1 + h*|X|)^2\"\"\"\n",
    "    X = rng.normal(0, 1, n)\n",
    "    e = rng.normal(0, sigma * (1 + h * np.abs(X)))\n",
    "    Y = beta * X + e\n",
    "    X1 = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X1).fit()\n",
    "    # HC1 robust\n",
    "    model_hc1 = model.get_robustcov_results(cov_type=\"HC1\")\n",
    "    return {\n",
    "        \"beta_hat\": model.params[1],\n",
    "        \"se_conventional\": model.bse[1],\n",
    "        \"se_hc1\": model_hc1.bse[1]\n",
    "    }\n",
    "\n",
    "def sim_hetero_many(R=1000, n=1000, beta=1.0, sigma=1.0, h=1.5):\n",
    "    out = [sim_hetero_once(n=n, beta=beta, sigma=sigma, h=h) for _ in range(R)]\n",
    "    bhats = np.array([d[\"beta_hat\"] for d in out])\n",
    "    se_conv = np.array([d[\"se_conventional\"] for d in out])\n",
    "    se_hc1  = np.array([d[\"se_hc1\"] for d in out])\n",
    "    return {\n",
    "        \"emp_sd_beta_hat\": bhats.std(ddof=1),\n",
    "        \"mean_se_conventional\": se_conv.mean(),\n",
    "        \"mean_se_hc1\": se_hc1.mean()\n",
    "    }\n",
    "\n",
    "res_het = sim_hetero_many(R=1000, n=1000, beta=1.0, sigma=1.0, h=1.5)\n",
    "res_het"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df92726e",
   "metadata": {},
   "source": [
    "### Week 9 – Question 2\n",
    "**Task:** Use a simulation to estimate the standard deviation of the coefficient when errors are highly correlated / non-independent, and compare these standard errors to those from OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "def sim_cluster_once(G=100, m=10, beta=1.0, tau=1.2, sigma=1.0):\n",
    "    \"\"\"DGP: G clusters, m obs per cluster (n = G*m).\n",
    "    X ~ N(0,1); errors have cluster shock u_g and idiosyncratic v.\n",
    "    Y = beta*X + e,  e = u_g + v\n",
    "    \"\"\"\n",
    "    n = G * m\n",
    "    g_id = np.repeat(np.arange(G), m)\n",
    "    X = rng.normal(0, 1, n)\n",
    "    u = rng.normal(0, tau, G)  # cluster shocks\n",
    "    v = rng.normal(0, sigma, n)\n",
    "    e = u[g_id] + v\n",
    "    Y = beta * X + e\n",
    "    X1 = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X1).fit()\n",
    "    # Cluster-robust by group id\n",
    "    model_clu = model.get_robustcov_results(cov_type=\"cluster\", groups=g_id)\n",
    "    return {\n",
    "        \"beta_hat\": model.params[1],\n",
    "        \"se_conventional\": model.bse[1],\n",
    "        \"se_cluster\": model_clu.bse[1]\n",
    "    }\n",
    "\n",
    "def sim_cluster_many(R=1000, G=100, m=10, beta=1.0, tau=1.2, sigma=1.0):\n",
    "    out = [sim_cluster_once(G=G, m=m, beta=beta, tau=tau, sigma=sigma) for _ in range(R)]\n",
    "    bhats = np.array([d[\"beta_hat\"] for d in out])\n",
    "    se_conv = np.array([d[\"se_conventional\"] for d in out])\n",
    "    se_clu  = np.array([d[\"se_cluster\"] for d in out])\n",
    "    return {\n",
    "        \"emp_sd_beta_hat\": bhats.std(ddof=1),\n",
    "        \"mean_se_conventional\": se_conv.mean(),\n",
    "        \"mean_se_cluster\": se_clu.mean()\n",
    "    }\n",
    "\n",
    "res_cluster = sim_cluster_many(R=1000, G=100, m=10, beta=1.0, tau=1.2, sigma=1.0)\n",
    "res_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326684e4",
   "metadata": {},
   "source": [
    "### Week 9 – Question 3\n",
    "**Task:** Show that with strong correlation, the bootstrap standard deviation of the coefficient (using naive iid residual bootstrap) can differ from the standard deviation from a full simulation of the DGP; show how this improves with a larger sample and a better bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "def dgp_cluster(G=40, m=8, beta=1.0, tau=3.0, sigma=1.0):\n",
    "    \"\"\"Strong intra-cluster correlation: rho = tau^2 / (tau^2 + sigma^2) ≈ 0.9.\"\"\"\n",
    "    n = G*m\n",
    "    g = np.repeat(np.arange(G), m)\n",
    "    X = rng.normal(0, 1, n)\n",
    "    u = rng.normal(0, tau, G)         # cluster shock\n",
    "    v = rng.normal(0, sigma, n)       # idiosyncratic\n",
    "    e = u[g] + v\n",
    "    Y = beta*X + e\n",
    "    return Y, X, g\n",
    "\n",
    "def iid_resid_boot_se(Y, X, B=800):\n",
    "    X1 = sm.add_constant(X)\n",
    "    base = sm.OLS(Y, X1).fit()\n",
    "    resid = base.resid\n",
    "    betas = []\n",
    "    for _ in range(B):\n",
    "        e_star = rng.choice(resid, size=len(resid), replace=True)  # WRONG under dependence\n",
    "        Y_star = base.fittedvalues + e_star\n",
    "        betas.append(sm.OLS(Y_star, X1).fit().params[1])\n",
    "    return np.std(betas, ddof=1)\n",
    "\n",
    "def cluster_boot_se(Y, X, groups, B=800):\n",
    "    # Resample entire clusters (block bootstrap)\n",
    "    X1 = sm.add_constant(X)\n",
    "    base = sm.OLS(Y, X1).fit()\n",
    "    betas = []\n",
    "    gids = np.unique(groups)\n",
    "    idx_by_g = {g: np.where(groups==g)[0] for g in gids}\n",
    "    for _ in range(B):\n",
    "        sample_g = rng.choice(gids, size=len(gids), replace=True)\n",
    "        idx = np.concatenate([idx_by_g[g] for g in sample_g])\n",
    "        betas.append(sm.OLS(Y[idx], X1[idx]).fit().params[1])\n",
    "    return np.std(betas, ddof=1)\n",
    "\n",
    "def empirical_sd_over_dgp(R=800, **dgp_kwargs):\n",
    "    bhats = []\n",
    "    for _ in range(R):\n",
    "        Y, X, g = dgp_cluster(**dgp_kwargs)\n",
    "        bhats.append(sm.OLS(Y, sm.add_constant(X)).fit().params[1])\n",
    "    return np.std(bhats, ddof=1)\n",
    "\n",
    "G, m = 40, 8\n",
    "Y, X, g = dgp_cluster(G=G, m=m)\n",
    "emp_sd = empirical_sd_over_dgp(R=800, G=G, m=m)\n",
    "se_iid  = iid_resid_boot_se(Y, X, B=800)\n",
    "se_clust= cluster_boot_se(Y, X, g, B=800)\n",
    "\n",
    "small_sample_results = {\n",
    "    \"empirical_SD_DGP\": emp_sd,\n",
    "    \"SE_naive_IID_boot\": se_iid,\n",
    "    \"SE_cluster_boot\": se_clust\n",
    "}\n",
    "small_sample_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger sample: more clusters and/or size per cluster\n",
    "G, m = 400, 20\n",
    "Y_big, X_big, g_big = dgp_cluster(G=G, m=m)\n",
    "emp_sd_big = empirical_sd_over_dgp(R=400, G=G, m=m)\n",
    "se_iid_big  = iid_resid_boot_se(Y_big, X_big, B=400)\n",
    "se_clust_big= cluster_boot_se(Y_big, X_big, g_big, B=400)\n",
    "\n",
    "large_sample_results = {\n",
    "    \"empirical_SD_DGP_big\": emp_sd_big,\n",
    "    \"SE_naive_IID_boot_big\": se_iid_big,\n",
    "    \"SE_cluster_boot_big\": se_clust_big\n",
    "}\n",
    "large_sample_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26457e",
   "metadata": {},
   "source": [
    "## Week 11 – Event Study Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4d06f",
   "metadata": {},
   "source": [
    "### Week 11 – Question 1(a)\n",
    "**Task:** Construct a dataset for an event study where the value, derivative, and second derivative of a trend all change discontinuously after an event, and build a model using only the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set up time and event\n",
    "T = 200\n",
    "t = np.arange(T)\n",
    "event_time = 100\n",
    "post = (t > event_time).astype(int)\n",
    "\n",
    "# Construct Y with different level, slope, and curvature after the event\n",
    "# Pre-event: mild quadratic\n",
    "# Post-event: bigger intercept, steeper slope, more curvature\n",
    "Y = np.where(\n",
    "    t <= event_time,\n",
    "    0.01 * t**2 + 0.1 * t,                       # pre-event trend\n",
    "    (0.03 * t**2 + 0.6 * t + 10),                # post-event trend: level, slope, curvature all changed\n",
    ")\n",
    "\n",
    "# Add noise\n",
    "Y = Y + np.random.normal(0, 1, size=T)\n",
    "\n",
    "# Model using ONLY the value (no explicit derivatives),\n",
    "# but allowing for a general trend via t and t^2\n",
    "X = np.column_stack([post, t, t**2])   # event indicator + time + time^2\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# The key question: is the event \"real\"?\n",
    "# That is, is the coefficient on `post` (the event dummy) significantly nonzero?\n",
    "beta_event = model.params[1]\n",
    "pval_event = model.pvalues[1]\n",
    "print(\"Event coefficient (beta_event):\", beta_event)\n",
    "print(\"p-value for event effect:\", pval_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d10e6f",
   "metadata": {},
   "source": [
    "## Week 12 – Difference-in-Differences with Violated Prior Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b9067",
   "metadata": {},
   "source": [
    "### Week 12 – Prior Trends Do Not Hold\n",
    "**Task:** Construct a dataset in which prior trends do not hold, and in which this makes the differences-in-differences estimate come out wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of observations per (group, time) cell\n",
    "n_per_cell = 100\n",
    "\n",
    "# Time periods and groups\n",
    "times = np.arange(-5, 5)        # -5, -4, ..., 4\n",
    "groups = np.array([0, 1])       # 0 = control, 1 = treatment\n",
    "\n",
    "# Create all (time, group) combinations and repeat within each cell\n",
    "time_grid, group_grid = np.meshgrid(times, groups, indexing='ij')\n",
    "time_vec = np.repeat(time_grid.ravel(), n_per_cell)\n",
    "group_vec = np.repeat(group_grid.ravel(), n_per_cell)\n",
    "\n",
    "# Indicator for post-treatment period\n",
    "post = (time_vec >= 0).astype(int)\n",
    "\n",
    "# Different pre-trends: treatment group has a steeper slope\n",
    "control_trend = 0.5 * time_vec\n",
    "treat_trend   = 1.0 * time_vec   # steeper line\n",
    "\n",
    "trend = np.where(group_vec == 0, control_trend, treat_trend)\n",
    "\n",
    "# True treatment effect\n",
    "true_effect = 2.0\n",
    "\n",
    "# Outcome with noise\n",
    "noise = np.random.normal(0, 1, len(time_vec))\n",
    "Y = trend + true_effect * post * group_vec + noise\n",
    "\n",
    "# Put into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Y\": Y,\n",
    "    \"Time\": time_vec,\n",
    "    \"Group\": group_vec,\n",
    "    \"Post\": post\n",
    "})\n",
    "\n",
    "# DID regression: Y ~ Group + Post + Group*Post\n",
    "df[\"interaction\"] = df[\"Group\"] * df[\"Post\"]\n",
    "X = sm.add_constant(df[[\"Group\", \"Post\", \"interaction\"]])\n",
    "res = sm.OLS(df[\"Y\"], X).fit()\n",
    "\n",
    "print(res.summary())\n",
    "print(\"True treatment effect:\", true_effect)\n",
    "print(\"Estimated DID effect:\", res.params[\"interaction\"])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
